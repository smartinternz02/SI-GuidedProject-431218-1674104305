{"cells": [{"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\nimport os, types\nimport pandas as pd\nfrom botocore.client import Config\nimport ibm_boto3\n\ndef __iter__(self): return 0\n\n# @hidden_cell\n# The following code accesses a file in your IBM Cloud Object Storage. It includes your credentials.\n# You might want to remove those credentials before you share the notebook.\ncos_client = ibm_boto3.client(service_name='s3',\n    ibm_api_key_id='SX1Gg9vqYrN4W2Rem-xZaGEfAKgjQuKWYheUyrVHL-3g',\n    ibm_auth_endpoint=\"https://iam.cloud.ibm.com/oidc/token\",\n    config=Config(signature_version='oauth'),\n    endpoint_url='https://s3.private.us.cloud-object-storage.appdomain.cloud')\n\nbucket = 'fakenewdetection-donotdelete-pr-xq8nniyiwmw5pi'\nobject_key = 'news.csv'\n\nbody = cos_client.get_object(Bucket=bucket,Key=object_key)['Body']\n# add missing __iter__ method, so pandas accepts body as file-like object\nif not hasattr(body, \"__iter__\"): body.__iter__ = types.MethodType( __iter__, body )\n\ndf = pd.read_csv(body)\ndf.head()\n", "execution_count": 2, "outputs": [{"output_type": "execute_result", "execution_count": 2, "data": {"text/plain": "   Unnamed: 0                                              title  \\\n0        8476                       You Can Smell Hillary\u2019s Fear   \n1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n2        3608        Kerry to go to Paris in gesture of sympathy   \n3       10142  Bernie supporters on Twitter erupt in anger ag...   \n4         875   The Battle of New York: Why This Primary Matters   \n\n                                                text label  \n0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n3  \u2014 Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n4  It's primary day in New York and front-runners...  REAL  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8476</td>\n      <td>You Can Smell Hillary\u2019s Fear</td>\n      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10294</td>\n      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3608</td>\n      <td>Kerry to go to Paris in gesture of sympathy</td>\n      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n      <td>REAL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10142</td>\n      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n      <td>\u2014 Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>875</td>\n      <td>The Battle of New York: Why This Primary Matters</td>\n      <td>It's primary day in New York and front-runners...</td>\n      <td>REAL</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "df.head()", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "   Unnamed: 0                                              title  \\\n0        8476                       You Can Smell Hillary\u2019s Fear   \n1       10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n2        3608        Kerry to go to Paris in gesture of sympathy   \n3       10142  Bernie supporters on Twitter erupt in anger ag...   \n4         875   The Battle of New York: Why This Primary Matters   \n\n                                                text label  \n0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  \n1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  \n2  U.S. Secretary of State John F. Kerry said Mon...  REAL  \n3  \u2014 Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  \n4  It's primary day in New York and front-runners...  REAL  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>title</th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8476</td>\n      <td>You Can Smell Hillary\u2019s Fear</td>\n      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10294</td>\n      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3608</td>\n      <td>Kerry to go to Paris in gesture of sympathy</td>\n      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n      <td>REAL</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10142</td>\n      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n      <td>\u2014 Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n      <td>FAKE</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>875</td>\n      <td>The Battle of New York: Why This Primary Matters</td>\n      <td>It's primary day in New York and front-runners...</td>\n      <td>REAL</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "X = df['text']  # independent variable\ny = df['label'] #dependent variable", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "\n# Create a series to store the labels: y\n#y = df.label\n\n# Create training set and test set\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.33, random_state=53)", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Initialize a CountVectorizer object: count_vectorizer\ncount_vectorizer = CountVectorizer(stop_words='english')", "execution_count": 7, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Transform the training data using only the 'text' column values: count_train\ncount_train = count_vectorizer.fit_transform(X_train)\n\n# Transform the test data using only the 'text' column values: count_test\ncount_test = count_vectorizer.transform(X_test)\n", "execution_count": 8, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Print the first 10 features of the count_vectorizer\nprint(count_vectorizer.get_feature_names()[:10])", "execution_count": 9, "outputs": [{"output_type": "stream", "text": "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n", "name": "stdout"}, {"output_type": "stream", "text": "/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Initialize a TfidfVectorizer object: tfidf_vectorizer\ntfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.7)\n\n# Transform the training data: tfidf_train\ntfidf_train = tfidf_vectorizer.fit_transform(X_train)\n\n# transform the test data: tfidf_test\ntfidf_test = tfidf_vectorizer.transform(X_test)\n\n# Print the first 10 features\nprint(tfidf_vectorizer.get_feature_names()[:10])\n\n# Print the first 5 vectors of the tfidf training data\nprint(tfidf_train.A[:5])", "execution_count": 10, "outputs": [{"output_type": "stream", "text": "['00', '000', '0000', '00000031', '000035', '00006', '0001', '0001pt', '000ft', '000km']\n[[0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]\n [0. 0. 0. ... 0. 0. 0.]]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "count_df = pd.DataFrame(count_train.A, columns=count_vectorizer.get_feature_names())\n\n# Create the TfidfVectorizer DataFrame: tfidf_df\ntfidf_df = pd.DataFrame(tfidf_train.A, columns=tfidf_vectorizer.get_feature_names())\n\n# Print the head of count_df\nprint(count_df.head())\n\n# Print the head of tfidf_df\nprint(tfidf_df.head())\n\n# Calculate the difference in columns: difference\ndifference = set(count_df.columns) - set(tfidf_df.columns)\nprint(difference)\n\n# Check whether the DataFrame are equal\nprint(count_df.equals(tfidf_df))", "execution_count": 11, "outputs": [{"output_type": "stream", "text": "   00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n0   0    0     0         0       0      0     0       0      0      0  ...   \n1   0    0     0         0       0      0     0       0      0      0  ...   \n2   0    0     0         0       0      0     0       0      0      0  ...   \n3   0    0     0         0       0      0     0       0      0      0  ...   \n4   0    0     0         0       0      0     0       0      0      0  ...   \n\n   \u062d\u0644\u0628  \u0639\u0631\u0628\u064a  \u0639\u0646  \u0644\u0645  \u0645\u0627  \u0645\u062d\u0627\u0648\u0644\u0627\u062a  \u0645\u0646  \u0647\u0630\u0627  \u0648\u0627\u0644\u0645\u0631\u0636\u0649  \u0e22\u0e07ade  \n0    0     0   0   0   0        0   0    0        0      0  \n1    0     0   0   0   0        0   0    0        0      0  \n2    0     0   0   0   0        0   0    0        0      0  \n3    0     0   0   0   0        0   0    0        0      0  \n4    0     0   0   0   0        0   0    0        0      0  \n\n[5 rows x 56922 columns]\n    00  000  0000  00000031  000035  00006  0001  0001pt  000ft  000km  ...  \\\n0  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n1  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n2  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n3  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n4  0.0  0.0   0.0       0.0     0.0    0.0   0.0     0.0    0.0    0.0  ...   \n\n   \u062d\u0644\u0628  \u0639\u0631\u0628\u064a   \u0639\u0646   \u0644\u0645   \u0645\u0627  \u0645\u062d\u0627\u0648\u0644\u0627\u062a   \u0645\u0646  \u0647\u0630\u0627  \u0648\u0627\u0644\u0645\u0631\u0636\u0649  \u0e22\u0e07ade  \n0  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n1  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n2  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n3  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n4  0.0   0.0  0.0  0.0  0.0      0.0  0.0  0.0      0.0    0.0  \n\n[5 rows x 56922 columns]\nset()\nFalse\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.naive_bayes import MultinomialNB\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# Instantiate a Multinomial Naive Bayes classifier: nb_classifier\nnb_classifier = MultinomialNB()\n\n# Fit the classifier to the training data\nnb_classifier.fit(count_train, y_train)\n\n# Create the predicted tags: pred\npred = nb_classifier.predict(count_test)\n\n# Calculate the accuracy score: score\nscore = accuracy_score(y_test, pred)\nprint(score)\n\n# Calculate the confusion matrix: cm\ncm =confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\nprint(cm)", "execution_count": 12, "outputs": [{"output_type": "stream", "text": "0.893352462936394\n[[ 865  143]\n [  80 1003]]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "count_test.shape", "execution_count": 13, "outputs": [{"output_type": "execute_result", "execution_count": 13, "data": {"text/plain": "(2091, 56922)"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "nb_classifier = MultinomialNB()\n\n# Fit the classifier to the training data\nnb_classifier.fit(tfidf_train, y_train)\n\n# Create the predicted tags: pred\npred = nb_classifier.predict(tfidf_test)\n\n# Calculate the accuracy score: score\nscore = accuracy_score(y_test, pred)\nprint(score)\n\n# Calculate the confusion matrix: cm\ncm = confusion_matrix(y_test, pred, labels=['FAKE', 'REAL'])\nprint(cm)", "execution_count": 14, "outputs": [{"output_type": "stream", "text": "0.8565279770444764\n[[ 739  269]\n [  31 1052]]\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "alphas = np.arange(0, 1, 0.1)\n\n# Define train_and_predict()\ndef train_and_predict(alpha):\n    # Instantiate the classifier: nb_classifier\n    nb_classifier = MultinomialNB(alpha=alpha)\n    \n    # Fit to the training data\n    nb_classifier.fit(tfidf_train, y_train)\n    \n    # Predict the labels: pred\n    pred = nb_classifier.predict(tfidf_test)\n    \n    # Compute accuracy: score\n    score = accuracy_score(y_test, pred)\n    return score\n\n# Iterate over the alphas and print the corresponding score\nfor alpha in alphas:\n    print('Alpha: ', alpha)\n    print('Score: ', train_and_predict(alpha))\n    print()", "execution_count": 15, "outputs": [{"output_type": "stream", "text": "Alpha:  0.0\nScore:  0.8813964610234337\n\nAlpha:  0.1\nScore:  0.8976566236250598\n\nAlpha:  0.2\nScore:  0.8938307030129125\n\nAlpha:  0.30000000000000004\nScore:  0.8900047824007652\n\nAlpha:  0.4\nScore:  0.8857006217120995\n\nAlpha:  0.5\nScore:  0.8842659014825442\n\nAlpha:  0.6000000000000001\nScore:  0.874701099952176\n\nAlpha:  0.7000000000000001\nScore:  0.8703969392635102\n\nAlpha:  0.8\nScore:  0.8660927785748446\n\nAlpha:  0.9\n", "name": "stdout"}, {"output_type": "stream", "text": "/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/sklearn/naive_bayes.py:555: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n  warnings.warn(\n", "name": "stderr"}, {"output_type": "stream", "text": "Score:  0.8589191774270684\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "class_labels = nb_classifier.classes_\n\n# Extract the features: feature_names\nfeature_names = tfidf_vectorizer.get_feature_names()\n\n# Zip the feature names together with the coefficient array \n# and sort by weights: feat_with_weights\nfeat_with_weights = sorted(zip(nb_classifier.coef_[0], feature_names))\n\n# Print the first class label and the top 20 feat_with_weights entries\nprint(class_labels[0], feat_with_weights[:20])\n\n# Print the second class label and the bottom 20 feat_with_weights entries\nprint(class_labels[1], feat_with_weights[-20:])", "execution_count": 16, "outputs": [{"output_type": "stream", "text": "FAKE [(-11.316312804238807, '0000'), (-11.316312804238807, '000035'), (-11.316312804238807, '0001'), (-11.316312804238807, '0001pt'), (-11.316312804238807, '000km'), (-11.316312804238807, '0011'), (-11.316312804238807, '006s'), (-11.316312804238807, '007'), (-11.316312804238807, '007s'), (-11.316312804238807, '008s'), (-11.316312804238807, '0099'), (-11.316312804238807, '00am'), (-11.316312804238807, '00p'), (-11.316312804238807, '00pm'), (-11.316312804238807, '014'), (-11.316312804238807, '015'), (-11.316312804238807, '018'), (-11.316312804238807, '01am'), (-11.316312804238807, '020'), (-11.316312804238807, '023')]\nREAL [(-7.742481952533027, 'states'), (-7.717550034444668, 'rubio'), (-7.703583809227384, 'voters'), (-7.654774992495461, 'house'), (-7.649398936153309, 'republicans'), (-7.6246184189367, 'bush'), (-7.616556675728881, 'percent'), (-7.545789237823644, 'people'), (-7.516447881078008, 'new'), (-7.448027933291952, 'party'), (-7.411148410203476, 'cruz'), (-7.410910239085596, 'state'), (-7.35748985914622, 'republican'), (-7.33649923948987, 'campaign'), (-7.2854057032685775, 'president'), (-7.2166878130917755, 'sanders'), (-7.108263114902301, 'obama'), (-6.724771332488041, 'clinton'), (-6.5653954389926845, 'said'), (-6.328486029596207, 'trump')]\n", "name": "stdout"}, {"output_type": "stream", "text": "/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n  warnings.warn(msg, category=FutureWarning)\n/opt/conda/envs/Python-3.9/lib/python3.9/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n  warnings.warn(msg, category=FutureWarning)\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "import pickle\npickle.dump(nb_classifier,open('fake_news.pkl','wb'))", "execution_count": 32, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "ls", "execution_count": 33, "outputs": [{"output_type": "stream", "text": "fake_news.pkl  fake_newspr.tgz  fake_news.tgz\r\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "!pip install watson-machine-learning-client", "execution_count": 18, "outputs": [{"output_type": "stream", "text": "Requirement already satisfied: watson-machine-learning-client in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (1.0.391)\nRequirement already satisfied: lomond in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.3.3)\nRequirement already satisfied: tqdm in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (4.62.3)\nRequirement already satisfied: ibm-cos-sdk in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: boto3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.18.21)\nRequirement already satisfied: certifi in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2022.9.24)\nRequirement already satisfied: requests in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (2.26.0)\nRequirement already satisfied: pandas in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.3.4)\nRequirement already satisfied: tabulate in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (0.8.9)\nRequirement already satisfied: urllib3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from watson-machine-learning-client) (1.26.7)\nRequirement already satisfied: botocore<1.22.0,>=1.21.21 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (1.21.41)\nRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.10.0)\nRequirement already satisfied: s3transfer<0.6.0,>=0.5.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from boto3->watson-machine-learning-client) (0.5.0)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (2.8.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.22.0,>=1.21.21->boto3->watson-machine-learning-client) (1.15.0)\nRequirement already satisfied: ibm-cos-sdk-s3transfer==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: ibm-cos-sdk-core==2.11.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from ibm-cos-sdk->watson-machine-learning-client) (2.11.0)\nRequirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (2.0.4)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from requests->watson-machine-learning-client) (3.3)\nRequirement already satisfied: pytz>=2017.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (2021.3)\nRequirement already satisfied: numpy>=1.17.3 in /opt/conda/envs/Python-3.9/lib/python3.9/site-packages (from pandas->watson-machine-learning-client) (1.20.3)\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "from ibm_watson_machine_learning import APIClient\nwml_credentials = {\n    \"url\": \"https://us-south.ml.cloud.ibm.com\",\n    \"apikey\": \"dQewyTGIYhChd0xuaHcpUJkRgGwn4qxQFflcgmQLCOO4\"\n}\nclient = APIClient(wml_credentials)", "execution_count": 19, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "client = APIClient(wml_credentials)", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "def guide_from_space_name(client, space_name):\n    space = client.spaces.get_details()\n    return(next(item for item in space['resources'] if item['entity']['name'] == space_name)['metadata']['id'])", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "space_uid = guide_from_space_name(client, 'fakenews_classification')\nprint(\"Space UID = \" +space_uid)", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "Space UID = b41cb89c-328a-48b9-b56a-0b2f917250cb\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "client.set.default_space(space_uid)", "execution_count": 23, "outputs": [{"output_type": "execute_result", "execution_count": 23, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "client.software_specifications.list()", "execution_count": 24, "outputs": [{"output_type": "stream", "text": "-----------------------------  ------------------------------------  ----\nNAME                           ASSET_ID                              TYPE\ndefault_py3.6                  0062b8c9-8b7d-44a0-a9b9-46c416adcbd9  base\nkernel-spark3.2-scala2.12      020d69ce-7ac1-5e68-ac1a-31189867356a  base\npytorch-onnx_1.3-py3.7-edt     069ea134-3346-5748-b513-49120e15d288  base\nscikit-learn_0.20-py3.6        09c5a1d0-9c1e-4473-a344-eb7b665ff687  base\nspark-mllib_3.0-scala_2.12     09f4cff0-90a7-5899-b9ed-1ef348aebdee  base\npytorch-onnx_rt22.1-py3.9      0b848dd4-e681-5599-be41-b5f6fccc6471  base\nai-function_0.1-py3.6          0cdb0f1e-5376-4f4d-92dd-da3b69aa9bda  base\nshiny-r3.6                     0e6e79df-875e-4f24-8ae9-62dcc2148306  base\ntensorflow_2.4-py3.7-horovod   1092590a-307d-563d-9b62-4eb7d64b3f22  base\npytorch_1.1-py3.6              10ac12d6-6b30-4ccd-8392-3e922c096a92  base\ntensorflow_1.15-py3.6-ddl      111e41b3-de2d-5422-a4d6-bf776828c4b7  base\nautoai-kb_rt22.2-py3.10        125b6d9a-5b1f-5e8d-972a-b251688ccf40  base\nruntime-22.1-py3.9             12b83a17-24d8-5082-900f-0ab31fbfd3cb  base\nscikit-learn_0.22-py3.6        154010fa-5b3b-4ac1-82af-4d5ee5abbc85  base\ndefault_r3.6                   1b70aec3-ab34-4b87-8aa0-a4a3c8296a36  base\npytorch-onnx_1.3-py3.6         1bc6029a-cc97-56da-b8e0-39c3880dbbe7  base\nkernel-spark3.3-r3.6           1c9e5454-f216-59dd-a20e-474a5cdf5988  base\npytorch-onnx_rt22.1-py3.9-edt  1d362186-7ad5-5b59-8b6c-9d0880bde37f  base\ntensorflow_2.1-py3.6           1eb25b84-d6ed-5dde-b6a5-3fbdf1665666  base\nspark-mllib_3.2                20047f72-0a98-58c7-9ff5-a77b012eb8f5  base\ntensorflow_2.4-py3.8-horovod   217c16f6-178f-56bf-824a-b19f20564c49  base\nruntime-22.1-py3.9-cuda        26215f05-08c3-5a41-a1b0-da66306ce658  base\ndo_py3.8                       295addb5-9ef9-547e-9bf4-92ae3563e720  base\nautoai-ts_3.8-py3.8            2aa0c932-798f-5ae9-abd6-15e0c2402fb5  base\ntensorflow_1.15-py3.6          2b73a275-7cbf-420b-a912-eae7f436e0bc  base\nkernel-spark3.3-py3.9          2b7961e2-e3b1-5a8c-a491-482c8368839a  base\npytorch_1.2-py3.6              2c8ef57d-2687-4b7d-acce-01f94976dac1  base\nspark-mllib_2.3                2e51f700-bca0-4b0d-88dc-5c6791338875  base\npytorch-onnx_1.1-py3.6-edt     32983cea-3f32-4400-8965-dde874a8d67e  base\nspark-mllib_3.0-py37           36507ebe-8770-55ba-ab2a-eafe787600e9  base\nspark-mllib_2.4                390d21f8-e58b-4fac-9c55-d7ceda621326  base\nautoai-ts_rt22.2-py3.10        396b2e83-0953-5b86-9a55-7ce1628a406f  base\nxgboost_0.82-py3.6             39e31acd-5f30-41dc-ae44-60233c80306e  base\npytorch-onnx_1.2-py3.6-edt     40589d0e-7019-4e28-8daa-fb03b6f4fe12  base\npytorch-onnx_rt22.2-py3.10     40e73f55-783a-5535-b3fa-0c8b94291431  base\ndefault_r36py38                41c247d3-45f8-5a71-b065-8580229facf0  base\nautoai-ts_rt22.1-py3.9         4269d26e-07ba-5d40-8f66-2d495b0c71f7  base\nautoai-obm_3.0                 42b92e18-d9ab-567f-988a-4240ba1ed5f7  base\npmml-3.0_4.3                   493bcb95-16f1-5bc5-bee8-81b8af80e9c7  base\nspark-mllib_2.4-r_3.6          49403dff-92e9-4c87-a3d7-a42d0021c095  base\nxgboost_0.90-py3.6             4ff8d6c2-1343-4c18-85e1-689c965304d3  base\npytorch-onnx_1.1-py3.6         50f95b2a-bc16-43bb-bc94-b0bed208c60b  base\nautoai-ts_3.9-py3.8            52c57136-80fa-572e-8728-a5e7cbb42cde  base\nspark-mllib_2.4-scala_2.11     55a70f99-7320-4be5-9fb9-9edb5a443af5  base\nspark-mllib_3.0                5c1b0ca2-4977-5c2e-9439-ffd44ea8ffe9  base\nautoai-obm_2.0                 5c2e37fa-80b8-5e77-840f-d912469614ee  base\nspss-modeler_18.1              5c3cad7e-507f-4b2a-a9a3-ab53a21dee8b  base\ncuda-py3.8                     5d3232bf-c86b-5df4-a2cd-7bb870a1cd4e  base\nautoai-kb_3.1-py3.7            632d4b22-10aa-5180-88f0-f52dfb6444d7  base\npytorch-onnx_1.7-py3.8         634d3cdc-b562-5bf9-a2d4-ea90a478456b  base\n-----------------------------  ------------------------------------  ----\nNote: Only first 50 records were displayed. To display more use 'limit' parameter.\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "software_spec_uid = client.software_specifications.get_uid_by_name(\"runtime-22.1-py3.9\")\nsoftware_spec_uid", "execution_count": 25, "outputs": [{"output_type": "execute_result", "execution_count": 25, "data": {"text/plain": "'12b83a17-24d8-5082-900f-0ab31fbfd3cb'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "import sklearn\nsklearn.__version__", "execution_count": 26, "outputs": [{"output_type": "execute_result", "execution_count": 26, "data": {"text/plain": "'1.0.2'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "model_details=client.repository.store_model(model='fake_news.tgz',\n            meta_props={\n                        client.repository.ModelMetaNames.NAME:\"NBModel\",\n                        client.repository.ModelMetaNames.TYPE:'scikit-learn_1.0',  \n                        client.repository.ModelMetaNames.SOFTWARE_SPEC_UID:software_spec_uid\n})\n", "execution_count": 34, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model_id=client.repository.get_model_id(model_details)", "execution_count": 35, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "model_id", "execution_count": 36, "outputs": [{"output_type": "execute_result", "execution_count": 36, "data": {"text/plain": "'6e71bef8-c1b1-4fe8-932e-b77158a90836'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.9", "language": "python"}, "language_info": {"name": "python", "version": "3.9.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}